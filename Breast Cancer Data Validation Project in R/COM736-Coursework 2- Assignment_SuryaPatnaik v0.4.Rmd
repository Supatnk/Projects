---------------------------------------------------------------------------------------------------------------------
COM736: Data Validation and Visualisation
CRN: 45947
Coursework 2- Assignment
----------------------------------------------------------------------------------------------------------------------
This item of coursework will contribute to 50% of the overall module mark. As part of this coursework, you are required to undertake data analysis and results visualisation of a data science problem, which may require discovering trends, making predictions and/or grouping objects/events. For this, you may take up the Wisconsin Breast Cancer Diagnostic datasets from the UCI Machine Learning Data Repository (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)). Analyse the problem using the following 7-step systematic approach.
You may like to use this file to  present your functioning code along with program outputs through this R Markdown document (http://rmarkdown.rstudio.com).   -----------------------------------------------------------------------------------------------------------------------  

Exercise 1. Reading and manually checking.

(a). View the Breast Cancer Diagnostic Datasets in a text-editor to determine its format and read the file into R. 
```{r}
setwd('C:\\Users\\surya\\Google Drive\\Ulster MSc Data Science\\COM736 ( 45947 ) - Data Valid and Visual. 2017-18\\Assessment\\COM736-Coursework 2- Assignment')
cancerds <- read.csv(file = "breast-cancer-wisconsin.csv", header = FALSE, col.names = c("Sample code number",
"Clump Thickness",
"Uniformity of Cell Size",
"Uniformity of Cell Shape",
"Marginal Adhesion",
"Single Epithelial Cell Size",
"Bare Nuclei",
"Bland Chromatin",
"Normal Nucleoli",
"Mitoses",
"Class"), stringsAsFactors=FALSE)

cancerds$Bare.Nuclei <- as.numeric(cancerds$Bare.Nuclei)

cancerds$Class <- ifelse(cancerds$Class == "2", "benign",
                          ifelse(cancerds$Class == "4", "malignant", NA))

cancerds$Class <- as.factor(cancerds$Class)

str(cancerds)
summary(cancerds$Class)
#summary(cancerds) # variable summary

#cancerds <- na.omit(cancerds)
#str(cancerds)

```

#Visualise the data check the outliers 
```{r}
library(ggplot2)
df <-data.frame(cancerds)
ggplot(stack(df[,2:10]), aes(x = ind, y = values)) + geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1, vjust=1)) +
  labs(title = "Boxplots of columns") + labs(x = "", y = "Values") + 
  scale_y_continuous(breaks = seq(1, 10, by = 1))

```

Find any missing data 

```{r}
# 16 observations are not complete , and 
# 683 observations are complete
summary(complete.cases(cancerds))

#96 observations are complete
Dataset_complete <- na.omit(cancerds)
summary(complete.cases(Dataset_complete))

#percentage of observations complete
mean(complete.cases(cancerds))*100


```


Does the data contain other special values? If it does, replace them with NA.

```{r}

is.special <- function(x){
if (is.numeric(x)) !is.finite(x) else is.na(x)
}

#the below summary confirms there are 16 values in Bare.Nuclei with special values

summary(sapply(cancerds,is.special))

#summary(sapply(Dataset_complete,is.special))

# the below code replaces the special value with NA
is.na(cancerds) <- sapply(cancerds,is.special)

```



Find if there are any outliers in numerical properties of the cancer dataset using boxplot and boxplot.stats. Retrieve the corrosponding observations and look at the other values.  Set the outliers to NA (or a value that you find more appropiate).

```{r}
a<- cancerds$Clump.Thickness
b<- cancerds$Uniformity.of.Cell.Size
c<- cancerds$Uniformity.of.Cell.Shape
d<- cancerds$Marginal.Adhesion
e<- cancerds$Single.Epithelial.Cell.Size
f<- cancerds$Bare.Nuclei
g<- cancerds$Bland.Chromatin
h<- cancerds$Normal.Nucleoli
i<- cancerds$Mitoses

Dataset_outlier <- cancerds

#Outliers plotted using boxplot 
#boxplot(w,x,y,z, coef = 1.5, names = c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width"))

boxplot(a,b,c,d,e,f,g,h,i, coef = 1.5, names = c("Clump.Thickness","Uniformity.of.Cell.Size","Uniformity.of.Cell.Shape","Marginal.Adhesion","Single.Epithelial.Cell.Size","Bare.Nuclei","Bland.Chromatin","Normal.Nucleoli","Mitoses"))


#There are some attributes with outliers, identify the outliers by $out

# value of 9 and 10 is the outlier 
Marginal.Adhesion_outlier <- boxplot(Dataset_outlier$Marginal.Adhesion, coef = 1.5)$out

# value of 8,9,10 are outlier 
Single.Epithelial.Cell.Size_outlier <- boxplot(Dataset_outlier$Single.Epithelial.Cell.Size, coef = 1.5)$out

#value of 9 and 10 is the outlier
Normal.Nucleoli_outlier <- boxplot(Dataset_outlier$Normal.Nucleoli, coef = 1.5)$out

# value of 10 is the outlier 
Bland.Chromatin_outlier <- boxplot(Dataset_outlier$Bland.Chromatin, coef = 1.5)$out

# lot of outliers
Mitoses_outlier <- boxplot(Dataset_outlier$Mitoses, coef = 1.5)$out

Dataset_outlier <- cancerds

#There are some attributes with outliers, identify the outliers by $out

# value of 9 and 10 is the outlier 
Marginal.Adhesion_outlier <- boxplot(Dataset_outlier$Marginal.Adhesion, coef = 1.5)$out

# value of 8,9,10 are outlier 
Single.Epithelial.Cell.Size_outlier <- boxplot(Dataset_outlier$Single.Epithelial.Cell.Size, coef = 1.5)$out

#value of 9 and 10 is the outlier
Normal.Nucleoli_outlier <- boxplot(Dataset_outlier$Normal.Nucleoli, coef = 1.5)$out

# value of 10 is the outlier 
Bland.Chromatin_outlier <- boxplot(Dataset_outlier$Bland.Chromatin, coef = 1.5)$out

# lot of outliers
Mitoses_outlier <- boxplot(Dataset_outlier$Mitoses, coef = 1.5)$out

#Updates cancerds - sets the outliers 

cancerds$Marginal.Adhesion[Marginal.Adhesion_outlier]
cancerds$Single.Epithelial.Cell.Size[Single.Epithelial.Cell.Size_outlier]
cancerds$Normal.Nucleoli[Normal.Nucleoli_outlier]
cancerds$Bland.Chromatin[Bland.Chromatin_outlier]
cancerds$Mitoses[Mitoses_outlier]

#Cancer_OutlierNA <- cancerds
#The following code sets the outliers to NA in a new dataframe called Cancer_OutlierNA
cancerds$Marginal.Adhesion <- ifelse(d %in% Marginal.Adhesion_outlier, NA, d)
cancerds$Single.Epithelial.Cell.Size <- ifelse(e %in% Single.Epithelial.Cell.Size_outlier, NA, e)
cancerds$Normal.Nucleoli <- ifelse(f %in% Normal.Nucleoli_outlier, NA, f)
cancerds$Bland.Chromatin <- ifelse(g %in% Bland.Chromatin_outlier, NA, g)
cancerds$Mitoses <- ifelse(h %in% Mitoses_outlier, NA, h)


#Marginal.Adhesion had 60 NA's
#Bare.Nuclei had 16 NA's
#Bland.Chromatin_outlier had 20 NA's
#Single.Epithelial.Cell.Size had 54 NA's
#Normal.Nucleoli had 157 outlier
#Chromatin_outlier had 20 NA's
#Mitoses_outlier had 240 NA's
# total 699 obs

Cancer_OutlierNA <- cancerds

summary(Cancer_OutlierNA)
str(Cancer_OutlierNA)

```

Use k-nearest neighbour (kNN) imputation of the Visualization and Imputation of Missing Values (VIM) package to impute all missing values.

```{r}
#Code for the above exercise.
library(VIM)
cancer_nona <- Cancer_OutlierNA
n <- nrow(cancer_nona)

#Check how many NAs are introduced.
cancer_nona[is.na(cancer_nona)]

cancerds_imputed <- kNN(cancer_nona)
str(cancerds_imputed)

library(ggplot2)
cancerds_NoNA <-data.frame(cancerds_imputed[,2:10])
ggplot(stack(cancerds_NoNA), aes(x = ind, y = values)) + geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1, vjust=1)) +
  labs(title = "Boxplots of columns") + labs(x = "", y = "Values") + 
  scale_y_continuous(breaks = seq(1, 10, by = 1))

```



Multivariate analysis using PCA prcomp 


```{r }
library(devtools)
library(ggplot2)
library(ggbiplot)
#cancerds_NoNA <- na.omit(cancerds)


pca_result <- prcomp(cancerds_NoNA, scale = TRUE)
names(pca_result)

#The rotation matrix provides the principal component loadings; each column of pca_result$rotation contains the corresponding principal component loading vector.As mentioned in the previous task, we change the sign to point eigenvectors in the positive direction.
pca_result$rotation <- -pca_result$rotation

pca_result$rotation 

#We can also obtain the principal components scores from our results as these are stored in the x list item of our results. However, we also want to make a slight sign adjustment to our scores to point them in the positive direction.
pca_result$x <- - pca_result$x
head(pca_result$x)
# clump thickness, marginal adhesion, mitoses and cell size seems to be aligned to PC1
biplot(pca_result, scale = 0)

#The variance explained by each principal component is obtained by squaring these values:
(VE <- pca_result$sdev^2)

#To compute the proportion of variance explained by each principal component, we simply divide the variance explained by each principal component by the total variance explained by all 9 principal components:
# The first two principal components make 62% i.e. 48 + 12
PVE <- VE / sum(VE)
round(PVE, 2)

# The Sree plot clearly shows that the elbow point where the PVS significantly drops is at 2 
# SO now we had 9 variables to start with and reduced to 2 explaining 62% of variability 
library(gridExtra)
PVEplot <- qplot(c(1:9), PVE) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("PVE") +
  ggtitle("Scree Plot") +
  ylim(0, 1)

# Cumulative PVE plot
cumPVE <- qplot(c(1:9), cumsum(PVE)) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab(NULL) + 
  ggtitle("Cumulative Scree Plot") +
  ylim(0,1)

grid.arrange(PVEplot, cumPVE, ncol = 2)

#Study correlation. 
library(corrplot)

#Correlation between PCs.
PCcor=cor(pca_result$x)
#Correlation plot.
corrplot(PCcor, order="hclust")
#Scatter plot.
ggplot(cancerds_NoNA, aes(x=pca_result$x[,1], y=pca_result$x[,2]))+geom_point()

# There is some positive correlation between PC5, PC3 and Pc9

#Correlation among variables of cancer datasets
Origcor=cor(cancerds_NoNA[,2:9])
#Correlation plot.
corrplot(Origcor, order="hclust")
#Scatter plot of
ggplot(cancerds_NoNA[,2:9], aes(x=cancerds_NoNA$Uniformity.of.Cell.Shape, y=cancerds_NoNA$Uniformity.of.Cell.Size))+geom_point()

#Scatter plot Clear relation
#PCs are correlated particularly Normal.Nucleoli & Bare.Nuclei
ggplot(cancerds_NoNA[,2:9], aes(x=cancerds_NoNA$Normal.Nucleoli, y=cancerds_NoNA$Bare.Nuclei))+geom_point()

g <- ggbiplot(pca_result, obs.scale = 1, var.scale = 1, groups = cancerds_NoNA$Class, ellipse = TRUE, circle = F, ellipse.prob=0.70)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal', legend.position = 'top')
print(g)

#there is some overlap in data distribution between the two classess.


```


```{r }
# Splitting the dataset into the Training set and Test set
#install.packages('caTools')
library(caTools)
set.seed(71)
split = sample.split(cancerds_NoNA$Class, SplitRatio = 0.7)
training_mydata = subset(cancerds_NoNA, split == TRUE)
test_mydata = subset(cancerds_NoNA, split == FALSE)

head(training_mydata)

#Step II : Run the random forest model.

# Apply random forest (rf) algorithm.
library(randomForest)
set.seed(71) 
rf <-randomForest(Class~.,data=training_mydata, ntree=500) 
print(rf)

#Note : If a dependent variable is a factor, classification is assumed, otherwise regression is assumed. If omitted, randomForest will run in unsupervised mode.


#Step III : Find the optimal mtry value.
#floor(sqrt(ncol(training_mydata) - 1))
# Find the optimal value of mtry.
mtry <- tuneRF(training_mydata[-1,-c(7,9)],training_mydata$Class, ntreeTry=500,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]

print(mtry)
print(best.m)

#Apply random forest (rf) with the optimal value of mtry.
set.seed(71)
rf <-randomForest(Creditability~.,data=training_mydata, mtry=best.m, importance=TRUE,ntree=500)
print(rf)
plot(rf)

#Evaluate variable importance
importance(rf)
varImpPlot(rf)


#Step IV: 
# Predicting the Test set results
y_pred = predict(rf, newdata = test_mydata)

# install.packages('MLmetrics')
library(MLmetrics)
# Making the Confusion Matrix
(cm = ConfusionMatrix(y_pred, test_mydata$Creditability))

(Classification.Accuracy <- 100*Accuracy(y_pred, test_mydata$Creditability))


#Predict and Calculate Performance Metrics.

#Prediction and Calculate Performance Metrics
pred1=predict(rf,newdata = test_mydata,type = "prob")

library(ROCR)
perf = prediction(pred1[,2], test_mydata$Creditability)

# 0. Accuracy.
acc = performance(perf, "acc")
plot(acc,main="Accuracy Curve for Random Forest",col=2,lwd=2)

# 1. Area under curve
auc = performance(perf, "auc")
auc@y.values[[1]]

# 2. True Positive and Negative Rate
pred3 = performance(perf, "tpr","fpr")

# 3. Plot the ROC curve
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
```

 Use one more classfier SVM 
